{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx": "hidden"
   },
   "source": [
    "### NOTE FOR LUCA\n",
    "\n",
    "**Remember to set/remove metadata as:**\n",
    "{\n",
    "  \"nbsphinx\": \"hidden\"\n",
    "}\n",
    "\n",
    "to enable/disable solutions view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Practical 11\n",
    "\n",
    "In this practical we will will see some other functionalities of Biopython.\n",
    "\n",
    "## Slides\n",
    "\n",
    "The slides of the introduction can be found here: [Intro](docs/Practical11.pdf)\n",
    "\n",
    "## Biopython\n",
    "\n",
    "From the Biopython tutorial: The Biopython Project is an international association of developers of freely available Python tools for computational molecular biology. The goal of Biopython is to make it as easy as possible to use Python for bioinformatics by creating high-quality, reusable modules and classes. Biopython features include parsers for various Bioinformatics file formats (BLAST, Clustalw, FASTA, Genbank,...), access to online services (NCBI, Expasy,...), interfaces to common and not-so-common programs (Clustalw, DSSP, MSMS...), a standard sequence class, various clustering modules, a KD tree data structure etc. and even documentation.\n",
    "\n",
    "In this practical we will see some features of Biopython but refer to [biopython documentation](http://biopython.org/wiki/Documentation) to discover all its features, recipes etc.\n",
    "\n",
    "These notes are largely based on what is available [here](http://biopython.org/DIST/docs/tutorial/Tutorial.pdf).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLAST\n",
    "\n",
    "[Blast (Basic logical alignment search tool)](https://www.ncbi.nlm.nih.gov/pubmed/2231712) is a well known tool to find similarities between biological sequences. It compares DNA or protein sequences and calculates the statistical significance of the matches found.\n",
    "\n",
    "The typical interaction with BLAST sees the user submit some sequences to the tool to get an alignment and then the hits are parsed to obtain information on the matches. Both these steps can be performed from within Biopython. Although it is possible to interact directly with a local installation of BLAST, in this practical we will work with the tool made available by NCBI (available [here](https://blast.ncbi.nlm.nih.gov/Blast.cgi)). \n",
    "\n",
    "### The function qblast\n",
    "\n",
    "The online version of blast can be accessed through the ```Bio.Blast.NCBIWWW.qblast()``` function.\n",
    "\n",
    "It's basic syntax is the following (first import ```from Bio.Blast import NCBIWWW```):\n",
    "\n",
    "```\n",
    "result_handle = Bio.Blast.NCBIWWW.qblast(blast_program, database, query_str)\n",
    "```\n",
    "where ```blast_program``` is the program to perform the alignment. The options are **blastn, blastp, blastx, tblast or tblastx**. ```database``` is the database to search against and ```query_str``` is a string containing the query to search against the database. The query can be a sequence or a fasta file entry or an identifier like a GI number (NCIBI's sequence identification number). Among the others, some optional parameters are the output format (```format_type``` that by default is \"XML\" which is the most stable output format but results can be stored also as text with \"Text\"). It is also possible to specify an expectation value cut-off to filter out alignments ```expect``` (the e-value threshold, default value is 10.0).\n",
    "\n",
    "Some databases to search against are reported below:\n",
    "\n",
    "![](img/pract11/blast_dbs.png)\n",
    "\n",
    "The query string can be obtained in different ways, for example it is possible to load sequences from a fasta file with:\n",
    "\n",
    "```\n",
    "from Bio.Blast import NCBIWWW\n",
    "fasta_string = open(\"myfile.fasta\").read()\n",
    "result_handle = NCBIWWW.qblast(\"blastn\", \"nt\", fasta_string)\n",
    "```\n",
    "\n",
    "or we can give a SeqRecord:\n",
    "\n",
    "```\n",
    "from Bio.Blast import NCBIWWW\n",
    "from Bio import SeqIO\n",
    "record = SeqIO.read(\"myfile.fasta\", format=\"fasta\")\n",
    "result_handle = NCBIWWW.qblast(\"blastn\", \"nt\", record.seq)\n",
    "```\n",
    "\n",
    "It is also possible to specify some optional parameters in the ```entrez_query``` for example we can limit the search to specific organisms with: ```entrez_query='\"Malus Domestica\" [Organism]'```.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** Let's align the first 100 bases of the first entry of the file [contigs82.fasta](file_samples/contigs82.fasta) to the Malus Domestica genome.\n",
    "\n",
    "**NOTE: this can take several minutes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning MDC020656.85 [GAGGGGTTTA...TTGGCAGCAA] to Malus Dom.\n"
     ]
    }
   ],
   "source": [
    "from Bio.Blast import NCBIWWW\n",
    "from Bio import SeqIO\n",
    "\n",
    "\n",
    "\n",
    "records = SeqIO.parse(\"file_samples/contigs82.fasta\", format=\"fasta\")\n",
    "rec = next(records)\n",
    "seq = rec.seq[0:100]\n",
    "print(\"Aligning {} [{}] to Malus Dom.\".format(rec.id,\n",
    "                                              seq[0:10]+\"...\"+seq[90:101]))\n",
    "result_handle = NCBIWWW.qblast(\"blastn\", \"nt\", \n",
    "                               seq,\n",
    "                               entrez_query='\"Malus Domestica\" [Organism]'\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the previous code does not output anything, it just returns a ```result_handle```. We need to parse it to get some results.\n",
    "\n",
    "### Parsing qblast output\n",
    "\n",
    "Once the qblast call returns, it gives the results in a handle object ```result_handle``` that we can parse or we can write to disk to avoid having to rerun the query other times. If we expect to get one alignment only, we can use the method **read** otherwise (if we have multiple query sequences) we should use the method **parse**: \n",
    "\n",
    "```\n",
    "blast_record = NCBIXML.read(result_handle)\n",
    "```\n",
    "\n",
    "or \n",
    "\n",
    "```\n",
    "blast_records = NCBIXML.parse(result_handle)\n",
    "```\n",
    "Note that to use these methods we first need to import the ```NCBIXML``` module with ```from Bio.Blast import NCBIXML```.\n",
    "\n",
    "These methods are analogous to what seen in the case of SeqIO and AlignIO. In the case of multiple entries we can loop through them with:\n",
    "\n",
    "```\n",
    "blast_records = NCBIXML.parse(result_handle)\n",
    "for record in blast_records:\n",
    "    #do something with it...\n",
    "    \n",
    "```\n",
    "or we can retrieve one record at a time with ```record = next(blast_records)```.\n",
    "\n",
    "\n",
    "### Saving results to file\n",
    "\n",
    "To save the results present in the result_handle we can simply write them to file. In case we have only one entry we can read it and write it to file:\n",
    "\n",
    "```\n",
    "out_f = open(\"my_blast_result.xml\", \"w\")\n",
    "out_f.write(result_handle.read())\n",
    "out_f.close \n",
    "result_handle.close()\n",
    "```\n",
    "If we have more than one entry we need to loop through all the entries and save them in the file:\n",
    "\n",
    "```\n",
    "out_f = open(\"my_blast_result.xml\", \"w\")\n",
    "for entry in result_handle.parse():\n",
    "    out_f.write(entry)\n",
    "out_f.close \n",
    "result_handle.close()\n",
    "```\n",
    "\n",
    "**Example:**\n",
    "\n",
    "Let's BLAST the galactosidase alpha (gi number: 2717) against the human database on NCBI and save the results to file. (**Note that it can take several seconds/minutes to run!**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Blast import NCBIWWW\n",
    "\n",
    "result_handle = NCBIWWW.qblast(\"blastn\", \"nt\", \"2717\")\n",
    "\n",
    "\n",
    "with open(\"file_samples/blast_res.xml\",\"w\") as out_f:\n",
    "    out_f.write(result_handle.read())\n",
    "\n",
    "result_handle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open a blast .XML file\n",
    "\n",
    "A BLAST output file can be read by opening the file to get the handler and then parse it with the method **parse** seen above:\n",
    "\n",
    "```\n",
    "from Bio.Blast import NCBIXML\n",
    "result_handle = open(\"my_blast.xml\")\n",
    "blast_records = NCBIXML.parse(result_handle)\n",
    "```\n",
    "This will end up in a handle to the blast results.\n",
    "\n",
    "\n",
    "### The BLAST record class\n",
    "\n",
    "The ```Bio.Blast.Record.Blast``` class holds the results of the alignment. In particular it is composed of the following three information:\n",
    "\n",
    "1. *query*: the identifier of the query (a string).\n",
    "\n",
    "2. *Descriptions* : a list of Description objects. Each ```Description``` holds the following information:\n",
    "\n",
    "    - ```Description.title``` : a string with the title of the hit;\n",
    "    - ```Description.score``` : a float with the score of the alignment;\n",
    "    - ```Description.num_alignments``` : an int with the number of alignments with the same subject;\n",
    "    - ```Description.e``` : a float with the e-value of the alignment.\n",
    "    \n",
    "3. *Alignments* : a list of Alignment objects. Each ```Alignment``` holds the following information:\n",
    "\n",
    "    - ```Alignment.title``` : a string with the title of the hit (identical to ```Description.title```);\n",
    "    - ```Alignment.length``` : an int with the length of the alignment;\n",
    "    - ```Alignment.hsps``` : a list of HSP objects (High Scoring Pair). Each ```HSP``` has the following info:\n",
    "        \n",
    "        - ```HSP.score``` : the BLAST score of the hit\n",
    "        - ```HSP.bits``` :  the bits score of the hit (x: on average 2^x pairs to find such a good hit by chance)\n",
    "        - ```HSP.expect``` : the evalue of the hit\n",
    "        - ```HSP.num_alignments``` : the number of alignments for the same subject\n",
    "        - ```HSP.identities``` : the number of identities between query and subject\n",
    "        - ```HSP.positives``` : the number of identical bases/aminos or having similar chemical properties\n",
    "        - ```HSP.gaps``` : the number of gaps between query and subject\n",
    "        - ```HSP.strand``` : a **tuple** with (query,subject) strands\n",
    "        - ```HSP.frame``` : a **tuple** with the frame shifts\n",
    "        - ```HSP.query/HSP.sbjct``` : query/subject sequence\n",
    "        - ```HSP.query_start/HSP.sbjct_start``` :query/subject start point\n",
    "        - ```HSP.match``` : the match sequence (basically \"|\" for matches and spaces for mismatches)\n",
    "        - ```HSP.align_length``` : the alignment length.\n",
    "\n",
    "More information on the BLAST record can be found [here](http://biopython.org/DIST/docs/api/Bio.Blast.Record-module.html).\n",
    "\n",
    "**Example:**\n",
    "\n",
    "Let's blast the serum albumin sequence (gi number [23307792](https://www.ncbi.nlm.nih.gov/nuccore/AF542069.1)) on the human genome and report all the information reported by BLAST. (warning might take a while to run!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Blast import NCBIWWW\n",
    "from Bio.Blast import NCBIXML\n",
    "\n",
    "result_handle = NCBIWWW.qblast(\"blastn\", \"nt\", \"23307792\", \n",
    "                               entrez_query='\"Homo Sapiens\" [Organism]'\n",
    "                               )\n",
    "\n",
    "\n",
    "\n",
    "for res in NCBIXML.parse(result_handle):\n",
    "    for d in res.descriptions:\n",
    "        \n",
    "        print(\"TITLE:{}\\nSCORE:{}\\nN.ALIGN:{}\\nE-VAL:{}\".format(\n",
    "            d.title,d.score, d.num_alignments,d.e))\n",
    "        \n",
    "    for a in res.alignments:\n",
    "        print(\"Align Title:{}\\nAlign Len: {}\".format(a.title, a.length))\n",
    "\n",
    "        \n",
    "    \n",
    "        for h in a.hsps:\n",
    "            s = h.score\n",
    "            b = h.bits\n",
    "            e = h.expect\n",
    "            n = h.num_alignments\n",
    "            i = h.identities\n",
    "            p = h.positives\n",
    "            g = h.gaps\n",
    "            st = h.strand\n",
    "            f = h.frame\n",
    "            q = h.query\n",
    "            sb = h.sbjct\n",
    "            qs = h.query_start\n",
    "            ss = h.sbjct_start\n",
    "            qe = h.query_end\n",
    "            se = h.sbjct_end\n",
    "            m = h.match \n",
    "            al = h.align_length\n",
    "            \n",
    "            print(\"Score: {} Bits: {} E-val: {}\".format(s,b,e))\n",
    "            print(\"N.aligns:{} Ident:{} Pos.:{} Gaps:{} Align len:{}\".format(\n",
    "                n,i,p,g,al))\n",
    "            print(\"Strand: {} Frame: {}\".format(st,f))\n",
    "            print(\"Query:\", q, \" start:\", qs, \" end:\", qe)\n",
    "            print(\"Match:\",m)\n",
    "            print(\"Subjc:\",sb, \" start:\", ss, \" end:\", se)\n",
    "            \n",
    "\n",
    "result_handle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** Let's align the first 100 bases of the first 5 entries of the file [contigs82.fasta](file_samples/contigs82.fasta) to the Malus Domestica genome, writing the results to a apple_first5.xml file.\n",
    "Sample output is here: [apple_first5.xml](file_samples/apple_first5.xml).\n",
    "**NOTE: this can take several minutes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Blast import NCBIWWW\n",
    "from Bio import SeqIO\n",
    "\n",
    "rc = SeqIO.parse(\"file_samples/contigs82.fasta\", format=\"fasta\")\n",
    "fasta_string = \"\"\n",
    "ids2align =[]\n",
    "for i in range(5):\n",
    "    entry = next(rc)\n",
    "    fasta_string +=\">\" + entry.id +\"\\n\"+entry.seq +\"\\n\"\n",
    "    ids2align.append(entry.id)\n",
    "print(\"Aligning the following {} entries:\\n\\t{}\".format(\n",
    "                                                    len(ids2align),\n",
    "                                                    \"\\n\\t\".join(ids2align)\n",
    "                                                    ))\n",
    "result_handle = NCBIWWW.qblast(\"blastn\", \"nt\", \n",
    "                               fasta_string,\n",
    "                               entrez_query='\"Malus Domestica\" [Organism]'\n",
    "                              )\n",
    "\n",
    "with open(\"file_samples/blast_res_apple.xml\",\"w\") as out_f:\n",
    "    out_f.write(result_handle.read())\n",
    "print(\"Output written to \\\"blast_res_apple.xml\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting data from NCBI\n",
    "\n",
    "Biopython provides a module (```Bio.Entrez```) to pull data off resources like PubMed or GenBank, and other repositories programmatically through [Entrez](http://www.ncbi.nlm.nih.gov/Entrez/). \n",
    "\n",
    "There are some limitations (mostly taken care directly by Biopython) that you should be aware of when you use NCBI's services (e.g. they recommend not to run more than 3 requests per second on weekdays, ...). Check [here](http://www.ncbi.nlm.nih.gov/books/NBK25497/#chapter2.Usage_Guidelines_and_Requiremen) if you want to learn what these limitations are.\n",
    "\n",
    "First of all we need to import the Entrez module with (```from Bio import Entrez```) and then we can start interacting with Entrez, then we should specify (optional) an email setting ```Entrez.email``` (this is optional but you get a warning if you do not specify it -- the email would be used to notify the user in case of excessive usage).\n",
    "\n",
    "In particular the module (complete info on [Entrez module are here](http://biopython.org/DIST/docs/api/Bio.Entrez-module.html)) provides, among the others, the following functions:\n",
    "\n",
    "1. ```res_handle = Entrez.einfo(db)``` returns a summary of the Entez databases as a results handle. ```db``` is an optional parameter specifying the resource of interest;\n",
    "2. ```res_handle = Entrez.esearch(db, term,id)``` returns all the entries in ```db``` having query matching the term ```term```. It is also possible to specify an ```id``` to get the information relative to that resource id;\n",
    "3. ```res_handle = Entrez.efetch(db, id, rettype, retmode)``` returns full record corresponding to the identifier ``id`` from the database ``db`` formatted in ```rettype``` (eg. gb, fasta,... [complete list](https://www.ncbi.nlm.nih.gov/books/NBK25499/table/chapter4.T._valid_values_of__retmode_and/?report=objectonly)) and return mode ```retmode``` (eg. text); \n",
    "4. ```res_handle = Entrez.esummary(db, id)``` returns the summary of the entry ```id``` from the database ```db``` as a handle;\n",
    "5. ```result = Entrez.read(res_handle)``` reads the information on the XML handle ```res_handle``` and stores them in a dictionary, list or string, depending on the case.  \n",
    "\n",
    "\n",
    "**Example:**\n",
    "\n",
    "Let's get a list of all available databases in Entrez as a dictionary. Let's then get a summary of the entries in 'sra'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "import datetime\n",
    "\n",
    "\n",
    "Entrez.email = \"my_email\"\n",
    "handle = Entrez.einfo()\n",
    "res = Entrez.read(handle)\n",
    "#print(res)\n",
    "print(\"\")\n",
    "print(\"As a list:\")\n",
    "print(res['DbList'])\n",
    "\n",
    "res = Entrez.read(Entrez.einfo(db = \"sra\"))\n",
    "#uncomment to see all the information captured\n",
    "#print(res)\n",
    "#for el in res[\"DbInfo\"].keys():\n",
    "#    print(el) \n",
    "date = res[\"DbInfo\"][\"LastUpdate\"]\n",
    "dt = datetime.datetime.strptime(date, \"%Y/%m/%d %H:%M\")\n",
    "print(\"\")\n",
    "print(\"Entries count: {:,}\".format(int(res[\"DbInfo\"][\"Count\"])))\n",
    "print(\"LastUpdate: {}/{}/{} {}:{}\".format(dt.day, \n",
    "                                          dt.month, \n",
    "                                          dt.year, \n",
    "                                          dt.hour,\n",
    "                                          dt.minute))\n",
    "print(\"Description:\", res[\"DbInfo\"][\"Description\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that effectively **einfo** returned a handler to an object that can be read by the **read** function that produces a dictionary. This dictionary had one key only \"DbList\" that is the list of available databases in the first case, while the key when db was specified is \"DbInfo\".\n",
    "\n",
    "**Example:**\n",
    "Fetch the first three entries (retmax = 3) in pubmed that are related to the species \"Malus Domestica\" and report the title of the publication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "\n",
    "Entrez.email = \"my_email\"\n",
    "handle = Entrez.esearch(db=\"pubmed\", term=\"Malus Domestica\", retmax = 3)\n",
    "res = Entrez.read(handle)\n",
    "for el in res.keys():\n",
    "    print(el , \" : \", res[el])\n",
    "\n",
    "print(\"\")\n",
    "for ids in res[\"IdList\"]:    \n",
    "    print(\"Results for id:\", ids)\n",
    "    handle = Entrez.esummary(db=\"pubmed\",  id = ids)\n",
    "    res = Entrez.read(handle)\n",
    "    #uncomment to see all info\n",
    "    #print(res)\n",
    "    for r in res:\n",
    "        print(r[\"Title\"])\n",
    "        print(r[\"Source\"])\n",
    "        print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:**\n",
    "Retrieve genbank formatted information of the Malus x domestica MYB domain class transcription factor (MYB1) mRNA complete cds (nucleotide database id:HM122614.1). Parse it as a SeqRecord, printing only the sequence (remember previous practical's SeqIO)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "from Bio import SeqIO\n",
    "\n",
    "Entrez.email = \"my_email\"\n",
    "handle = Entrez.efetch(db=\"nucleotide\", \n",
    "                       id = \"HM122614.1\", \n",
    "                       rettype = \"gb\", \n",
    "                       retmode=\"text\")\n",
    "my_seq = SeqIO.read(handle, format = \"genbank\")\n",
    "print(handle.read())\n",
    "print(my_seq)\n",
    "print(\"\")\n",
    "print(\"SEQUENCE:\")\n",
    "print(my_seq.seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting data from ExPASy\n",
    "\n",
    "Similarly to what done with Entrez, it is possible to pull data out of ExPASy (https://www.expasy.org/) through the Bio.ExPASy module. We will not cover this in detail. All information can be found here: [Bio.ExPASy module](http://biopython.org/DIST/docs/api/Bio.ExPASy-module.html#__package__).\n",
    "\n",
    "As an example, we will see how to download a couple of SwissProt entries (the human, rhesus macaque and mouse P53 protein) and perform pairwise sequence alignment of Human vs Macaque and Human vs Mouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import ExPASy\n",
    "from Bio import SwissProt\n",
    "from Bio import pairwise2\n",
    "\n",
    "#the ids of the human, rhesus and mouse proteins\n",
    "accessions = [\"P04637\", \"P56424\", \"P02340\"] \n",
    "sequences = []\n",
    "for accession in accessions:\n",
    "    handle = ExPASy.get_sprot_raw(accession)\n",
    "    record = SwissProt.read(handle)\n",
    "    print(\"Organism: {}\".format(record.organism))\n",
    "    print(record.entry_name)\n",
    "    print(\",\".join(record.accessions))\n",
    "    print(record.keywords)\n",
    "    \n",
    "    print(record.sequence[:30] + \"...\")\n",
    "    sequences.append(record.sequence)\n",
    "\n",
    "print(\"\\n\\nPairwise sequence alignment of Human vs Rhesus P53:\")\n",
    "\n",
    "aligns = pairwise2.align.globalxx(sequences[0],sequences[1])\n",
    "for al in aligns[0:3]:\n",
    "    print(\"Score {}:\".format(al[2]))\n",
    "    print(al[0][0:50])\n",
    "    print(al[1][0:50])\n",
    "    \n",
    "print(\"\\n\\nPairwise sequence alignment of Human vs Mouse P53:\")\n",
    "\n",
    "aligns = pairwise2.align.globalxx(sequences[0],sequences[2])\n",
    "for al in aligns[0:3]:\n",
    "    print(\"Score {}:\".format(al[2]))\n",
    "    print(al[0][0:50])\n",
    "    print(al[1][0:50])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find [here](http://biopython.org/DIST/docs/api/toc-Bio.SeqRecord-module.html) all the details on how to deal with the SwissProt records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D structure and PDB\n",
    "\n",
    "Biopython can also deal with data coming from the [Protein Data Bank database](https://www.rcsb.org/pdb/home/home.do). It is a database of structural information of 3D shapes of proteins, nucleic acids, and complex assemblies. The database currently contains more than 157,000 total structures.\n",
    "\n",
    "To deal with this kind of data we first need to import Biopython's module ```Bio.PDB``` with ```from Bio.PDB import *```. All the information on this module can be found [here](http://biopython.org/DIST/docs/api/Bio.PDB-module.html#__package__). \n",
    "\n",
    "It is possible to download a structure directly from PDB by using a ```PDBList``` object that features a function called ```download_pdb_files``` having the basic syntax:\n",
    "\n",
    "```\n",
    "PDBList.download_pdb_files(pdb_codes, pdir, file_format)\n",
    "\n",
    "```\n",
    "that downloads the ```file_format``` formatted structures defined in the ```pdb_codes``` list of 4 symbols structure Ids from PDB, stores them in the directory ```pdir```. The safer ```file_format``` to use is \"mmCif\". The function will not download the structures more than once. If a file is already present in the specified directory, a message **Structure exists** will be displayed. \n",
    "\n",
    "**Example:**\n",
    "\n",
    "Let's programmatically download two different structures of the DNA polymerase [3C2K](https://www.rcsb.org/pdb/explore/explore.do?structureId=3C2K) and [3C2L](https://www.rcsb.org/pdb/explore/explore.do?structureId=3C2L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.PDB import *\n",
    "\n",
    "pdbl = PDBList()\n",
    "structures = [\"3C2K\", \"3C2L\"]\n",
    "el = pdbl.download_pdb_files(structures, \n",
    "                             file_format = \"mmCif\", \n",
    "                             pdir = \"file_samples/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Macromolecular Crystallographic Information Files (mmCif files .cif) is a paired collection of names (starting with \"\\_\") and values.They also contain a description of the 3D placement of every crystalized atom of the structure. A detailed description of the format can be found [here](http://mmcif.wwpdb.org/docs/tutorials/mechanics/pdbx-mmcif-syntax.html).  \n",
    "\n",
    "Once the structures are available locally, one can start parsing them to do something useful.\n",
    "Parsing can be done through the ```MMCIFParser``` object:\n",
    "\n",
    "```\n",
    "parser = MMCIFParser()\n",
    "```\n",
    "\n",
    "The ```parser``` object has several methods able to deal with structures. One of these is the ```get_structure``` that creates a ```PDB.Structure.Structure``` object with all the data present in the structure file.\n",
    "\n",
    "The basic syntax is:\n",
    "```\n",
    "structure = parser.get_structure(pdb_code, filename)\n",
    "```\n",
    "\n",
    "where ```pdb_code``` is the PDB code of the structure contained in the file ```filename```. The method returns a ```PDB.Structure.Structure``` that contains one or more models.  \n",
    "\n",
    "\n",
    "A ```Structure``` consists of a collection of one or more ```Model``` (different 3D conformations of the very same structure) that is a collection of ```Chain``` that is a collection of ```Residues``` that is a collection of ```Atoms```. Look in the documentation to get the information on each of these classes. This is the diagram of a structure:\n",
    "\n",
    "![](img/pract11/structure1.png)\n",
    "\n",
    "Given a ```Structure``` we can obtain iterators to **models**, **chains**, **residues** or **atoms** with:\n",
    "\n",
    "```\n",
    "Structure.get_models() \n",
    "Structure.get_chains()\n",
    "Structure.get_residues()\n",
    "Structure.get_atoms()\n",
    "```\n",
    "\n",
    "For each model obtained with ```structure.get_models()``` function we can loop through its chains, residues and atoms. For atoms we can get the 3D coordinates with ```Atom.get_coord()```.\n",
    "\n",
    "**Example:**\n",
    "Let's loop through all the models, chain, residues and atoms of the DNA polymerase structure 3C2K. Print the 3D coordinates of each atom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.PDB import *\n",
    "\n",
    "\n",
    "parser = MMCIFParser(QUIET=True) #To disable warnings\n",
    "\n",
    "\n",
    "filename = \"file_samples/3c2l.cif\"\n",
    "structure = parser.get_structure(\"3c2l\", filename)\n",
    "\n",
    "for model in structure.get_models():\n",
    "    print(\"model\", model, \"has {} chains\".format(len(model)))\n",
    "    \n",
    "    for chain in model:\n",
    "        print(\" - chain \", chain, \"has {} residues\".format(len(chain)))\n",
    "        \n",
    "        for residue in chain:\n",
    "            print (\"      - residue\", residue.get_resname(), \"has {} atoms\".format(len(residue)))\n",
    "            \n",
    "            for atom in residue:\n",
    "                x,y,z = atom.get_coord()\n",
    "                print(\"        - atom:\", atom.get_name(), \"x: {} y:{} z:{}\".format(x,y,z))\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the coordinates of an atom we can compute distances between atoms or angles. We can also align two structures rototranslating the two to minimize their distance. We will not cover this and many other features that are provided by Biopython, such as Pyhlogentic analysis tools, interface towards pathways in KEGG, clustering, etc. If you are interested can find all the features available in the [Biopython tutorial](http://biopython.org/DIST/docs/tutorial/Tutorial.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write a python script that retrieves all the information present in SRA regarding PacBio sequencing performed on E.coli strain K12 (query term is \"E.coli K12 wgs PacBio\"). Print the number of results and for each id report the title, the accession id, the total number of spots and total number of bases sequenced. \n",
    "\n",
    "Sample output: \n",
    "```\n",
    "Entries found: 10\n",
    "Results for id: 6705337\n",
    " - acc=\"SRR8154667\"\n",
    " - total_spots=\"163482\"\n",
    " - total_bases=\"1561717136\"\n",
    "Results for id: 6705336\n",
    " - acc=\"SRR8154668\"\n",
    " - total_spots=\"163482\"\n",
    " - total_bases=\"897324802\"\n",
    "Results for id: 6705335\n",
    " - acc=\"SRR8154669\"\n",
    " - total_spots=\"163482\"\n",
    " - total_bases=\"1570240924\"\n",
    " \n",
    " ...\n",
    " ...\n",
    "```\n",
    "\n",
    "<div class=\"tggle\" onclick=\"toggleVisibility('ex2a');\">Show/Hide Solution</div>\n",
    "<div id=\"ex2a\" style=\"display:none;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "%reset -s -f\n",
    "\n",
    "from Bio import Entrez\n",
    "\n",
    "Entrez.email = \"my_email\"\n",
    "handle = Entrez.esearch(db=\"sra\", term=\"E.coli K12 wgs PacBio\", retmax = 10)\n",
    "res = Entrez.read(handle)\n",
    "#uncomment to see all fields:\n",
    "#for el in res.keys():\n",
    "#    print(el , \" : \", res[el])\n",
    "print(\"Entries found: {}\".format(res[\"Count\"]))\n",
    "\n",
    "\n",
    "for ids in res[\"IdList\"]:    \n",
    "    print(\"Results for id:\", ids)\n",
    "    handle = Entrez.esummary(db=\"sra\",  id = ids)\n",
    "    res = Entrez.read(handle)\n",
    "    #uncomment to see all info\n",
    "    #print(res)\n",
    "    for r in res:\n",
    "        info = r['ExpXml']\n",
    "        #print(info)\n",
    "        runs = r['Runs']\n",
    "        #some text parsing to do:\n",
    "        title = info.split(\"Title>\")\n",
    "        #print(title)\n",
    "        #print(title[1][:-2])\n",
    "        #print(runs)\n",
    "        r = runs.split(\" \")\n",
    "        #print(r)\n",
    "        print(\" - {}\\n - {}\\n - {}\".format(r[1],\n",
    "                                           r[2],\n",
    "                                           r[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Write a python function that reads all the entries of a blast alignment file in .xml format (like [blast_res_apple.xml](file_samples/blast_res_apple.xml) and outputs all the HSPs (see example below) having bitscore > B, alignment length >  A and minimum percentage of identity > I, where B, A and I are input thresholds. Hint: implement a filtering function: *filterHSPs(align, minBitscore = 0, minAlignLen = 0, minPercIdent = 0.1)*.\n",
    "\n",
    "```\n",
    "Alignments of MDC020656.85\n",
    "\tMDC020656.85: 1939-2593\n",
    "\tgi|125995253|dbj|AB270792.1|: 201263-201917\n",
    "\tScore:820.917 AlignLen:579 Id/Len:0.8812785388127854\n",
    "\tMDC020656.85: 1446-1935\n",
    "\tgi|125995253|dbj|AB270792.1|: 306490-306017\n",
    "\tScore:582.873 AlignLen:428 Id/Len:0.8629032258064516\n",
    "    ....\n",
    "    ....\n",
    "```\n",
    "\n",
    "that is reporting the HSP with query start-end position, subject start-end position, score, alignment length and number of identities / alignment length. \n",
    "\n",
    "<div class=\"tggle\" onclick=\"toggleVisibility('ex0');\">Show/Hide Solution</div>\n",
    "<div id=\"ex0\" style=\"display:none;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "%reset -s -f\n",
    "\n",
    "from Bio.Blast import NCBIXML\n",
    "\n",
    "\n",
    "def filterHSPs(align, minBitscore = 0, minAlignLen = 0, minPercIdent = 0.1):\n",
    "    ret = []\n",
    "\n",
    "    for h in align.hsps:\n",
    "            b = h.bits\n",
    "            i = h.identities \n",
    "            al = h.align_length\n",
    "            toOut = ((b > minBitscore) and \n",
    "                    (al > minAlignLen) and\n",
    "                    (i/al > minPercIdent))\n",
    "\n",
    "            \n",
    "            \n",
    "            if(toOut):\n",
    "                qs = h.query_start\n",
    "                ss = h.sbjct_start\n",
    "                qe = h.query_end\n",
    "                se = h.sbjct_end\n",
    "                ret.append([qs,qe, ss,se, b, i, al])\n",
    "             \n",
    "    return ret        \n",
    "\n",
    "result_handle = open(\"file_samples/blast_res_apple.xml\")\n",
    "\n",
    "\n",
    "for res in NCBIXML.parse(result_handle):\n",
    "    print(\"Alignments of {}\".format(res.query))\n",
    "    for align in res.alignments:\n",
    "        filtered = filterHSPs(align, 300, 50, 0.8)\n",
    "        if(len(filtered) > 0):\n",
    "            for h in filtered:\n",
    "                title = align.title.split( )[0]\n",
    "                print(\"\\t{}: {}-{}\".format(res.query,h[0],h[1]))\n",
    "                print(\"\\t{}: {}-{}\".format(title,h[2],h[3]))\n",
    "                print(\"\\tScore:{} AlignLen:{} Id/Len:{}\".format(\n",
    "                                                                h[4],\n",
    "                                                                h[5],\n",
    "                                                                h[5]/h[6]\n",
    "                                                               ))\n",
    "            \n",
    "    \n",
    "\n",
    "            \n",
    "\n",
    "result_handle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Write a python function ```retrieve_sequences(search_term, number, outfile)``` that retrieves the first ```number``` of sequences from NCBI's \"nucleotide\" database having a search  term  ```term``` (hint: use term and retmax parameters of Entrez.esearch) and stores them in a fasta file ```outfile``` (hint: use SeqIO.write). Test your code retrieving the first 5 entries having search term \"starch AND Malus Domestica [Organism]\"\n",
    "\n",
    "<div class=\"tggle\" onclick=\"toggleVisibility('ex1');\">Show/Hide Solution</div>\n",
    "<div id=\"ex1\" style=\"display:none;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "%reset -s -f\n",
    "\n",
    "from Bio import Entrez\n",
    "from Bio import SeqIO\n",
    "\n",
    "def retrieve_sequences(search_term, number, filename):\n",
    "    Entrez.email = \"my_email\"\n",
    "    handle = Entrez.esearch(db=\"nucleotide\", \n",
    "                            term=search_term, \n",
    "                            retmax=5)\n",
    "    res = Entrez.read(handle)\n",
    "    records = []\n",
    "    for el in res[\"IdList\"]:\n",
    "        handle = Entrez.efetch(db=\"nucleotide\", \n",
    "                               id=el, \n",
    "                               rettype = \"gb\", \n",
    "                               retmode=\"text\")\n",
    "        my_seq = SeqIO.read(handle, format = \"genbank\")\n",
    "        records.append(my_seq)\n",
    "    N = SeqIO.write(records, filename, \"fasta\")\n",
    "    print(\"Search term was: \", search_term)\n",
    "    print(\"{} sequences written to {}\".format(N,filename))\n",
    "    \n",
    "s_term = \"starch AND Malus Domestica [Organism]\"\n",
    "retrieve_sequences(s_term, 5, \"file_samples/starch_sequences.fasta\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Write a python function that aligns the sequences  in the file created in exercise 3. ([here](file_samples/starch_sequences.fasta) you can find mine) against the NCBI nr database limiting the hits to the Malus Domestica organism (parameter entrez_query='\"Malus Domestica\" [Organism]' in qblast)and prints to screen the following info for each hsp: \n",
    "    1. The title;\n",
    "    2. Score and e-value;\n",
    "    3. The number of alignments on the same subject, the number of identities and positives and the alignment length;\n",
    "    4. The number of mismatches and the list of their positions (hint: you can use the match string and look for \" \").\n",
    "   \n",
    "\n",
    "    \n",
    "<div class=\"tggle\" onclick=\"toggleVisibility('ex2');\">Show/Hide Solution</div>\n",
    "<div id=\"ex2\" style=\"display:none;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "from Bio.Blast import NCBIWWW\n",
    "from Bio.Blast import NCBIXML\n",
    "\n",
    "fasta_string = open(\"file_samples/starch_sequences.fasta\").read()\n",
    "\n",
    "res_handle = NCBIWWW.qblast(\"blastn\", \"nt\", fasta_string, \n",
    "                            entrez_query='\"Malus Domestica\" [Organism]'\n",
    "                           )\n",
    "\n",
    "for align in NCBIXML.parse(res_handle):\n",
    "    \n",
    "    for a in align.alignments:\n",
    "            print(\"Align Title:{}\".format(a.title))\n",
    "            \n",
    "            for h in a.hsps:\n",
    "                s = h.score\n",
    "                e = h.expect\n",
    "                n = h.num_alignments\n",
    "                i = h.identities\n",
    "                p = h.positives\n",
    "                m = h.match \n",
    "                al = h.align_length\n",
    "                misM = [str(x) for x in range(len(m)) if m[x] == \" \"]\n",
    "                print(\"Score: {} E-val: {}\".format(s,e))\n",
    "                print(\"N.aligns:{} Ident:{} Pos.:{} Align len:{}\".format(\n",
    "                    n,i,p,al))\n",
    "                if(len(misM)):\n",
    "                    print(\"Num mismatches:\",len(misM))\n",
    "                    print(\"Mismatch pos:\", \",\".join(misM))\n",
    "                else:\n",
    "                    print(\"No mismatches\")\n",
    "                print(\"\")\n",
    "            \n",
    "\n",
    "res_handle.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Write a python function ```getPublicationInfo(title_term,other_term)``` that retrieves the first 20 pubmed publications having the ```title_term``` in the title and ```other_term``` somewhere else in the text (hint use: \"Title\" and \"[Other Term]\" as esearch parameter term). For each publication print: \n",
    "    1. the title\n",
    "    2. authors \n",
    "    3. journal \n",
    "    4. year of publication (hint: get and split properly the \"PubDate\" entry)\n",
    "    5. a link to the pubmed entry (hint: it is the string \"https://www.ncbi.nlm.nih.gov/pubmed/\" followed by the pubmed id (\"eid\" entry of the dictionary \"ArticleIds\"). es: https://www.ncbi.nlm.nih.gov/pubmed/26919684\n",
    "\n",
    "Hint: to see how to combine search terms test them here: [https://www.ncbi.nlm.nih.gov/pubmed/advanced](https://www.ncbi.nlm.nih.gov/pubmed/advanced).\n",
    "\n",
    "Test your code calling ```getPublicationInfo(\"apple\",\"drought\")```\n",
    "\n",
    "<div class=\"tggle\" onclick=\"toggleVisibility('ex3');\">Show/Hide Solution</div>\n",
    "<div id=\"ex3\" style=\"display:none;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "\n",
    "from Bio import Entrez\n",
    "\n",
    "def getPublicationInfo(title_term,other_term): \n",
    "    Entrez.email = \"my_email\"\n",
    "    s_term = title_term + \" [Title] AND \" + other_term + \" [Other Term]\"\n",
    "    handle = Entrez.esearch(db=\"pubmed\", term=s_term)\n",
    "    res = Entrez.read(handle)\n",
    "#uncomment to see all info\n",
    "#    for el in res.keys():\n",
    "#        print(el , \" : \", res[el])\n",
    "#\n",
    "#    print(\"\")\n",
    "    for ids in res[\"IdList\"]:    \n",
    "        handle = Entrez.esummary(db=\"pubmed\",  id = ids)\n",
    "        res = Entrez.read(handle)\n",
    "        #uncomment to see all info\n",
    "        #print(res)\n",
    "        for r in res:\n",
    "            print(r[\"Title\"])\n",
    "            print(\",\".join(r[\"AuthorList\"]))\n",
    "            print(r[\"Source\"])\n",
    "            print(r[\"PubDate\"].split()[0])\n",
    "            print(\"https://www.ncbi.nlm.nih.gov/pubmed/\" + r[\"ArticleIds\"][\"eid\"])\n",
    "            print(\"\")\n",
    "            \n",
    "getPublicationInfo(\"apple\",\"drought\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Write some python code to retrieve the structure of two forms of the aspartate transcarbamoylase (PDB ids: 4FYW and 1D09). If you are interested, read more about the Aspartate Transcarbamoylase [here](http://pdb101.rcsb.org/motm/215). Write a function that gets the .cif file name and prints:\n",
    "\n",
    "    1. the number of chains, residues and atoms present in the file;\n",
    "    2. a histogram of the residues (plotting it with matplotlib) that are not water (encoded as \"HOH\");\n",
    "    3. a link to an online tool to visualize the 3D structure. The link will be \"http://www.rcsb.org/pdb/ngl/ngl.do?pdbid=\" followed by the PDB id of the protein (e.g. 1d09).\n",
    "\n",
    "<div class=\"tggle\" onclick=\"toggleVisibility('ex4');\">Show/Hide Solution</div>\n",
    "<div id=\"ex4\" style=\"display:none;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "from Bio.PDB import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def printCifInfo(filename):\n",
    "    \n",
    "    parser = MMCIFParser(QUIET=True) #To disable warnings\n",
    "    id = filename.split(\"/\")[1].split(\".\")[0]\n",
    "\n",
    "    structure = parser.get_structure(id, filename)\n",
    "    chains = structure.get_chains()\n",
    "    residues = structure.get_residues()\n",
    "    \n",
    "    atoms = structure.get_atoms()\n",
    "    res_histo = {}\n",
    "    resCnt = 0 #need this because while reading the residues \n",
    "               #I am pulling stuff out of the iterator\n",
    "    for res in residues:\n",
    "        rname = res.get_resname()\n",
    "        if(rname != \"HOH\"):\n",
    "            if( rname not in res_histo):\n",
    "                res_histo[rname] = 1\n",
    "            else:\n",
    "                res_histo[rname] += 1\n",
    "        resCnt += 1    \n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.bar(res_histo.keys(), res_histo.values())\n",
    "    plt.show()\n",
    "    print(\"Number of chains: {}\".format(len(list(chains))))\n",
    "    print(\"Number of residues: {}\".format(resCnt))\n",
    "    print(\"Number of atoms: {}\".format(len(list(atoms))))\n",
    "    print(\"http://www.rcsb.org/pdb/ngl/ngl.do?pdbid=\" + id) \n",
    "\n",
    "pdbl = PDBList()\n",
    "structures = [\"1D09\", \"4FYW\"]\n",
    "el = pdbl.download_pdb_files(structures, file_format = \"mmCif\", pdir = \"file_samples/\")\n",
    "\n",
    "printCifInfo(\"file_samples/1d09.cif\")\n",
    "printCifInfo(\"file_samples/4fyw.cif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</div>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
